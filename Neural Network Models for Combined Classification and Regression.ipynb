{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e21d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6b0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D://DS//Stater_Projects//abalone.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06cf434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path,header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdabd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b3b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.523992</td>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.139516</td>\n",
       "      <td>0.828742</td>\n",
       "      <td>0.359367</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>0.238831</td>\n",
       "      <td>9.933684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.099240</td>\n",
       "      <td>0.041827</td>\n",
       "      <td>0.490389</td>\n",
       "      <td>0.221963</td>\n",
       "      <td>0.109614</td>\n",
       "      <td>0.139203</td>\n",
       "      <td>3.224169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1            2            3            4            5  \\\n",
       "count  4177.000000  4177.000000  4177.000000  4177.000000  4177.000000   \n",
       "mean      0.523992     0.407881     0.139516     0.828742     0.359367   \n",
       "std       0.120093     0.099240     0.041827     0.490389     0.221963   \n",
       "min       0.075000     0.055000     0.000000     0.002000     0.001000   \n",
       "25%       0.450000     0.350000     0.115000     0.441500     0.186000   \n",
       "50%       0.545000     0.425000     0.140000     0.799500     0.336000   \n",
       "75%       0.615000     0.480000     0.165000     1.153000     0.502000   \n",
       "max       0.815000     0.650000     1.130000     2.825500     1.488000   \n",
       "\n",
       "                 6            7            8  \n",
       "count  4177.000000  4177.000000  4177.000000  \n",
       "mean      0.180594     0.238831     9.933684  \n",
       "std       0.109614     0.139203     3.224169  \n",
       "min       0.000500     0.001500     1.000000  \n",
       "25%       0.093500     0.130000     8.000000  \n",
       "50%       0.171000     0.234000     9.000000  \n",
       "75%       0.253000     0.329000    11.000000  \n",
       "max       0.760000     1.005000    29.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851878b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447b452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = df[:, 1:-1], df[:, -1]\n",
    "features, target = features.astype('float'), target.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2421fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ae0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f36f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20864828",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff812c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "88/88 - 1s - loss: 115.3841\n",
      "Epoch 2/200\n",
      "88/88 - 0s - loss: 92.2579\n",
      "Epoch 3/200\n",
      "88/88 - 0s - loss: 46.1514\n",
      "Epoch 4/200\n",
      "88/88 - 0s - loss: 10.4045\n",
      "Epoch 5/200\n",
      "88/88 - 0s - loss: 7.4323\n",
      "Epoch 6/200\n",
      "88/88 - 0s - loss: 7.3733\n",
      "Epoch 7/200\n",
      "88/88 - 0s - loss: 7.3099\n",
      "Epoch 8/200\n",
      "88/88 - 0s - loss: 7.1806\n",
      "Epoch 9/200\n",
      "88/88 - 0s - loss: 7.0955\n",
      "Epoch 10/200\n",
      "88/88 - 0s - loss: 7.0243\n",
      "Epoch 11/200\n",
      "88/88 - 0s - loss: 6.9610\n",
      "Epoch 12/200\n",
      "88/88 - 0s - loss: 6.8383\n",
      "Epoch 13/200\n",
      "88/88 - 0s - loss: 6.7807\n",
      "Epoch 14/200\n",
      "88/88 - 0s - loss: 6.6884\n",
      "Epoch 15/200\n",
      "88/88 - 0s - loss: 6.5871\n",
      "Epoch 16/200\n",
      "88/88 - 0s - loss: 6.4028\n",
      "Epoch 17/200\n",
      "88/88 - 0s - loss: 6.2897\n",
      "Epoch 18/200\n",
      "88/88 - 0s - loss: 6.2114\n",
      "Epoch 19/200\n",
      "88/88 - 0s - loss: 6.0807\n",
      "Epoch 20/200\n",
      "88/88 - 0s - loss: 5.9937\n",
      "Epoch 21/200\n",
      "88/88 - 0s - loss: 5.8757\n",
      "Epoch 22/200\n",
      "88/88 - 0s - loss: 5.7482\n",
      "Epoch 23/200\n",
      "88/88 - 0s - loss: 5.7009\n",
      "Epoch 24/200\n",
      "88/88 - 0s - loss: 5.5968\n",
      "Epoch 25/200\n",
      "88/88 - 0s - loss: 5.5315\n",
      "Epoch 26/200\n",
      "88/88 - 0s - loss: 5.4438\n",
      "Epoch 27/200\n",
      "88/88 - 0s - loss: 5.4192\n",
      "Epoch 28/200\n",
      "88/88 - 0s - loss: 5.3862\n",
      "Epoch 29/200\n",
      "88/88 - 0s - loss: 5.3882\n",
      "Epoch 30/200\n",
      "88/88 - 0s - loss: 5.3268\n",
      "Epoch 31/200\n",
      "88/88 - 0s - loss: 5.2731\n",
      "Epoch 32/200\n",
      "88/88 - 0s - loss: 5.2797\n",
      "Epoch 33/200\n",
      "88/88 - 0s - loss: 5.2242\n",
      "Epoch 34/200\n",
      "88/88 - 0s - loss: 5.2462\n",
      "Epoch 35/200\n",
      "88/88 - 0s - loss: 5.1964\n",
      "Epoch 36/200\n",
      "88/88 - 0s - loss: 5.2206\n",
      "Epoch 37/200\n",
      "88/88 - 0s - loss: 5.1651\n",
      "Epoch 38/200\n",
      "88/88 - 0s - loss: 5.2005\n",
      "Epoch 39/200\n",
      "88/88 - 0s - loss: 5.1698\n",
      "Epoch 40/200\n",
      "88/88 - 0s - loss: 5.1540\n",
      "Epoch 41/200\n",
      "88/88 - 0s - loss: 5.1620\n",
      "Epoch 42/200\n",
      "88/88 - 0s - loss: 5.1124\n",
      "Epoch 43/200\n",
      "88/88 - 0s - loss: 5.1435\n",
      "Epoch 44/200\n",
      "88/88 - 0s - loss: 5.1247\n",
      "Epoch 45/200\n",
      "88/88 - 0s - loss: 5.1093\n",
      "Epoch 46/200\n",
      "88/88 - 0s - loss: 5.1206\n",
      "Epoch 47/200\n",
      "88/88 - 0s - loss: 5.0979\n",
      "Epoch 48/200\n",
      "88/88 - 0s - loss: 5.0997\n",
      "Epoch 49/200\n",
      "88/88 - 0s - loss: 5.1074\n",
      "Epoch 50/200\n",
      "88/88 - 0s - loss: 5.0993\n",
      "Epoch 51/200\n",
      "88/88 - 0s - loss: 5.1131\n",
      "Epoch 52/200\n",
      "88/88 - 0s - loss: 5.0833\n",
      "Epoch 53/200\n",
      "88/88 - 0s - loss: 5.0635\n",
      "Epoch 54/200\n",
      "88/88 - 0s - loss: 5.1047\n",
      "Epoch 55/200\n",
      "88/88 - 0s - loss: 5.0573\n",
      "Epoch 56/200\n",
      "88/88 - 0s - loss: 5.0721\n",
      "Epoch 57/200\n",
      "88/88 - 0s - loss: 5.0475\n",
      "Epoch 58/200\n",
      "88/88 - 0s - loss: 5.0335\n",
      "Epoch 59/200\n",
      "88/88 - 0s - loss: 5.0281\n",
      "Epoch 60/200\n",
      "88/88 - 0s - loss: 5.1341\n",
      "Epoch 61/200\n",
      "88/88 - 0s - loss: 5.0598\n",
      "Epoch 62/200\n",
      "88/88 - 0s - loss: 5.0284\n",
      "Epoch 63/200\n",
      "88/88 - 0s - loss: 5.0150\n",
      "Epoch 64/200\n",
      "88/88 - 0s - loss: 5.0197\n",
      "Epoch 65/200\n",
      "88/88 - 0s - loss: 5.0003\n",
      "Epoch 66/200\n",
      "88/88 - 0s - loss: 4.9992\n",
      "Epoch 67/200\n",
      "88/88 - 0s - loss: 5.0292\n",
      "Epoch 68/200\n",
      "88/88 - 0s - loss: 4.9867\n",
      "Epoch 69/200\n",
      "88/88 - 0s - loss: 5.0242\n",
      "Epoch 70/200\n",
      "88/88 - 0s - loss: 5.0201\n",
      "Epoch 71/200\n",
      "88/88 - 0s - loss: 4.9792\n",
      "Epoch 72/200\n",
      "88/88 - 0s - loss: 4.9759\n",
      "Epoch 73/200\n",
      "88/88 - 0s - loss: 4.9799\n",
      "Epoch 74/200\n",
      "88/88 - 0s - loss: 4.9845\n",
      "Epoch 75/200\n",
      "88/88 - 0s - loss: 4.9591\n",
      "Epoch 76/200\n",
      "88/88 - 0s - loss: 4.9981\n",
      "Epoch 77/200\n",
      "88/88 - 0s - loss: 4.9598\n",
      "Epoch 78/200\n",
      "88/88 - 0s - loss: 4.9988\n",
      "Epoch 79/200\n",
      "88/88 - 0s - loss: 4.9824\n",
      "Epoch 80/200\n",
      "88/88 - 0s - loss: 4.9469\n",
      "Epoch 81/200\n",
      "88/88 - 0s - loss: 4.9339\n",
      "Epoch 82/200\n",
      "88/88 - 0s - loss: 4.9312\n",
      "Epoch 83/200\n",
      "88/88 - 0s - loss: 4.9403\n",
      "Epoch 84/200\n",
      "88/88 - 0s - loss: 4.9451\n",
      "Epoch 85/200\n",
      "88/88 - 0s - loss: 4.9428\n",
      "Epoch 86/200\n",
      "88/88 - 0s - loss: 4.9459\n",
      "Epoch 87/200\n",
      "88/88 - 0s - loss: 4.9897\n",
      "Epoch 88/200\n",
      "88/88 - 0s - loss: 4.9302\n",
      "Epoch 89/200\n",
      "88/88 - 0s - loss: 4.9186\n",
      "Epoch 90/200\n",
      "88/88 - 0s - loss: 4.9097\n",
      "Epoch 91/200\n",
      "88/88 - 0s - loss: 4.9284\n",
      "Epoch 92/200\n",
      "88/88 - 0s - loss: 4.9343\n",
      "Epoch 93/200\n",
      "88/88 - 0s - loss: 4.9105\n",
      "Epoch 94/200\n",
      "88/88 - 0s - loss: 4.9051\n",
      "Epoch 95/200\n",
      "88/88 - 0s - loss: 4.9104\n",
      "Epoch 96/200\n",
      "88/88 - 0s - loss: 4.9098\n",
      "Epoch 97/200\n",
      "88/88 - 0s - loss: 4.9318\n",
      "Epoch 98/200\n",
      "88/88 - 0s - loss: 4.9108\n",
      "Epoch 99/200\n",
      "88/88 - 0s - loss: 4.8834\n",
      "Epoch 100/200\n",
      "88/88 - 0s - loss: 4.8932\n",
      "Epoch 101/200\n",
      "88/88 - 0s - loss: 4.8973\n",
      "Epoch 102/200\n",
      "88/88 - 0s - loss: 4.9073\n",
      "Epoch 103/200\n",
      "88/88 - 0s - loss: 4.9283\n",
      "Epoch 104/200\n",
      "88/88 - 0s - loss: 4.8805\n",
      "Epoch 105/200\n",
      "88/88 - 0s - loss: 4.8770\n",
      "Epoch 106/200\n",
      "88/88 - 0s - loss: 4.8769\n",
      "Epoch 107/200\n",
      "88/88 - 0s - loss: 4.9082\n",
      "Epoch 108/200\n",
      "88/88 - 0s - loss: 4.8753\n",
      "Epoch 109/200\n",
      "88/88 - 0s - loss: 4.8787\n",
      "Epoch 110/200\n",
      "88/88 - 0s - loss: 4.8949\n",
      "Epoch 111/200\n",
      "88/88 - 0s - loss: 4.8747\n",
      "Epoch 112/200\n",
      "88/88 - 0s - loss: 4.8870\n",
      "Epoch 113/200\n",
      "88/88 - 0s - loss: 4.8644\n",
      "Epoch 114/200\n",
      "88/88 - 0s - loss: 4.8500\n",
      "Epoch 115/200\n",
      "88/88 - 0s - loss: 4.8730\n",
      "Epoch 116/200\n",
      "88/88 - 0s - loss: 4.8704\n",
      "Epoch 117/200\n",
      "88/88 - 0s - loss: 4.8697\n",
      "Epoch 118/200\n",
      "88/88 - 0s - loss: 4.8424\n",
      "Epoch 119/200\n",
      "88/88 - 0s - loss: 4.8417\n",
      "Epoch 120/200\n",
      "88/88 - 0s - loss: 4.8861\n",
      "Epoch 121/200\n",
      "88/88 - 0s - loss: 4.8432\n",
      "Epoch 122/200\n",
      "88/88 - 0s - loss: 4.8375\n",
      "Epoch 123/200\n",
      "88/88 - 0s - loss: 4.8245\n",
      "Epoch 124/200\n",
      "88/88 - 0s - loss: 4.8552\n",
      "Epoch 125/200\n",
      "88/88 - 0s - loss: 4.8500\n",
      "Epoch 126/200\n",
      "88/88 - 0s - loss: 4.8477\n",
      "Epoch 127/200\n",
      "88/88 - 0s - loss: 4.8323\n",
      "Epoch 128/200\n",
      "88/88 - 0s - loss: 4.8370\n",
      "Epoch 129/200\n",
      "88/88 - 0s - loss: 4.8263\n",
      "Epoch 130/200\n",
      "88/88 - 0s - loss: 4.8210\n",
      "Epoch 131/200\n",
      "88/88 - 0s - loss: 4.8287\n",
      "Epoch 132/200\n",
      "88/88 - 0s - loss: 4.8463\n",
      "Epoch 133/200\n",
      "88/88 - 0s - loss: 4.8412\n",
      "Epoch 134/200\n",
      "88/88 - 0s - loss: 4.8363\n",
      "Epoch 135/200\n",
      "88/88 - 0s - loss: 4.8511\n",
      "Epoch 136/200\n",
      "88/88 - 0s - loss: 4.8745\n",
      "Epoch 137/200\n",
      "88/88 - 0s - loss: 4.8350\n",
      "Epoch 138/200\n",
      "88/88 - 0s - loss: 4.8092\n",
      "Epoch 139/200\n",
      "88/88 - 0s - loss: 4.8187\n",
      "Epoch 140/200\n",
      "88/88 - 0s - loss: 4.8163\n",
      "Epoch 141/200\n",
      "88/88 - 0s - loss: 4.8174\n",
      "Epoch 142/200\n",
      "88/88 - 0s - loss: 4.8484\n",
      "Epoch 143/200\n",
      "88/88 - 0s - loss: 4.8112\n",
      "Epoch 144/200\n",
      "88/88 - 0s - loss: 4.7958\n",
      "Epoch 145/200\n",
      "88/88 - 0s - loss: 4.8152\n",
      "Epoch 146/200\n",
      "88/88 - 0s - loss: 4.8126\n",
      "Epoch 147/200\n",
      "88/88 - 0s - loss: 4.8093\n",
      "Epoch 148/200\n",
      "88/88 - 0s - loss: 4.8022\n",
      "Epoch 149/200\n",
      "88/88 - 0s - loss: 4.8524\n",
      "Epoch 150/200\n",
      "88/88 - 0s - loss: 4.8037\n",
      "Epoch 151/200\n",
      "88/88 - 0s - loss: 4.8219\n",
      "Epoch 152/200\n",
      "88/88 - 0s - loss: 4.8060\n",
      "Epoch 153/200\n",
      "88/88 - 0s - loss: 4.8124\n",
      "Epoch 154/200\n",
      "88/88 - 0s - loss: 4.8104\n",
      "Epoch 155/200\n",
      "88/88 - 0s - loss: 4.7970\n",
      "Epoch 156/200\n",
      "88/88 - 0s - loss: 4.8268\n",
      "Epoch 157/200\n",
      "88/88 - 0s - loss: 4.8064\n",
      "Epoch 158/200\n",
      "88/88 - 0s - loss: 4.8025\n",
      "Epoch 159/200\n",
      "88/88 - 0s - loss: 4.7854\n",
      "Epoch 160/200\n",
      "88/88 - 0s - loss: 4.7955\n",
      "Epoch 161/200\n",
      "88/88 - 0s - loss: 4.8123\n",
      "Epoch 162/200\n",
      "88/88 - 0s - loss: 4.7928\n",
      "Epoch 163/200\n",
      "88/88 - 0s - loss: 4.8024\n",
      "Epoch 164/200\n",
      "88/88 - 0s - loss: 4.7745\n",
      "Epoch 165/200\n",
      "88/88 - 0s - loss: 4.8325\n",
      "Epoch 166/200\n",
      "88/88 - 0s - loss: 4.7611\n",
      "Epoch 167/200\n",
      "88/88 - 0s - loss: 4.8100\n",
      "Epoch 168/200\n",
      "88/88 - 0s - loss: 4.8028\n",
      "Epoch 169/200\n",
      "88/88 - 0s - loss: 4.8188\n",
      "Epoch 170/200\n",
      "88/88 - 0s - loss: 4.8161\n",
      "Epoch 171/200\n",
      "88/88 - 0s - loss: 4.7954\n",
      "Epoch 172/200\n",
      "88/88 - 0s - loss: 4.7710\n",
      "Epoch 173/200\n",
      "88/88 - 0s - loss: 4.7754\n",
      "Epoch 174/200\n",
      "88/88 - 0s - loss: 4.7938\n",
      "Epoch 175/200\n",
      "88/88 - 0s - loss: 4.8003\n",
      "Epoch 176/200\n",
      "88/88 - 0s - loss: 4.7669\n",
      "Epoch 177/200\n",
      "88/88 - 0s - loss: 4.8048\n",
      "Epoch 178/200\n",
      "88/88 - 0s - loss: 4.7726\n",
      "Epoch 179/200\n",
      "88/88 - 0s - loss: 4.7597\n",
      "Epoch 180/200\n",
      "88/88 - 0s - loss: 4.7819\n",
      "Epoch 181/200\n",
      "88/88 - 0s - loss: 4.8063\n",
      "Epoch 182/200\n",
      "88/88 - 0s - loss: 4.7679\n",
      "Epoch 183/200\n",
      "88/88 - 0s - loss: 4.7693\n",
      "Epoch 184/200\n",
      "88/88 - 0s - loss: 4.7612\n",
      "Epoch 185/200\n",
      "88/88 - 0s - loss: 4.7952\n",
      "Epoch 186/200\n",
      "88/88 - 0s - loss: 4.7477\n",
      "Epoch 187/200\n",
      "88/88 - 0s - loss: 4.7736\n",
      "Epoch 188/200\n",
      "88/88 - 0s - loss: 4.7818\n",
      "Epoch 189/200\n",
      "88/88 - 0s - loss: 4.7593\n",
      "Epoch 190/200\n",
      "88/88 - 0s - loss: 4.7799\n",
      "Epoch 191/200\n",
      "88/88 - 0s - loss: 4.7475\n",
      "Epoch 192/200\n",
      "88/88 - 0s - loss: 4.7546\n",
      "Epoch 193/200\n",
      "88/88 - 0s - loss: 4.7696\n",
      "Epoch 194/200\n",
      "88/88 - 0s - loss: 4.7374\n",
      "Epoch 195/200\n",
      "88/88 - 0s - loss: 4.7528\n",
      "Epoch 196/200\n",
      "88/88 - 0s - loss: 4.7470\n",
      "Epoch 197/200\n",
      "88/88 - 0s - loss: 4.7481\n",
      "Epoch 198/200\n",
      "88/88 - 0s - loss: 4.7578\n",
      "Epoch 199/200\n",
      "88/88 - 0s - loss: 4.7842\n",
      "Epoch 200/200\n",
      "88/88 - 0s - loss: 4.7440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15290991c08>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train, target_train, epochs=200, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee7d677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4189f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = mean_absolute_error(target_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "670fccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.607\n"
     ]
    }
   ],
   "source": [
    "print('MAE: %.3f' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27b7f4",
   "metadata": {},
   "source": [
    "### Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5cbe05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = LabelEncoder().fit_transform(target)\n",
    "n_class = len(unique(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5df36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.33, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6b91347",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(n_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3db727cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "88/88 - 0s - loss: 3.2711\n",
      "Epoch 2/200\n",
      "88/88 - 0s - loss: 2.9289\n",
      "Epoch 3/200\n",
      "88/88 - 0s - loss: 2.6170\n",
      "Epoch 4/200\n",
      "88/88 - 0s - loss: 2.4519\n",
      "Epoch 5/200\n",
      "88/88 - 0s - loss: 2.3639\n",
      "Epoch 6/200\n",
      "88/88 - 0s - loss: 2.3097\n",
      "Epoch 7/200\n",
      "88/88 - 0s - loss: 2.2742\n",
      "Epoch 8/200\n",
      "88/88 - 0s - loss: 2.2456\n",
      "Epoch 9/200\n",
      "88/88 - 0s - loss: 2.2220\n",
      "Epoch 10/200\n",
      "88/88 - 0s - loss: 2.2022\n",
      "Epoch 11/200\n",
      "88/88 - 0s - loss: 2.1871\n",
      "Epoch 12/200\n",
      "88/88 - 0s - loss: 2.1734\n",
      "Epoch 13/200\n",
      "88/88 - 0s - loss: 2.1614\n",
      "Epoch 14/200\n",
      "88/88 - 0s - loss: 2.1496\n",
      "Epoch 15/200\n",
      "88/88 - 0s - loss: 2.1419\n",
      "Epoch 16/200\n",
      "88/88 - 0s - loss: 2.1319\n",
      "Epoch 17/200\n",
      "88/88 - 0s - loss: 2.1223\n",
      "Epoch 18/200\n",
      "88/88 - 0s - loss: 2.1144\n",
      "Epoch 19/200\n",
      "88/88 - 0s - loss: 2.1077\n",
      "Epoch 20/200\n",
      "88/88 - 0s - loss: 2.0986\n",
      "Epoch 21/200\n",
      "88/88 - 0s - loss: 2.0910\n",
      "Epoch 22/200\n",
      "88/88 - 0s - loss: 2.0841\n",
      "Epoch 23/200\n",
      "88/88 - 0s - loss: 2.0765\n",
      "Epoch 24/200\n",
      "88/88 - 0s - loss: 2.0713\n",
      "Epoch 25/200\n",
      "88/88 - 0s - loss: 2.0637\n",
      "Epoch 26/200\n",
      "88/88 - 0s - loss: 2.0578\n",
      "Epoch 27/200\n",
      "88/88 - 0s - loss: 2.0528\n",
      "Epoch 28/200\n",
      "88/88 - 0s - loss: 2.0456\n",
      "Epoch 29/200\n",
      "88/88 - 0s - loss: 2.0417\n",
      "Epoch 30/200\n",
      "88/88 - 0s - loss: 2.0379\n",
      "Epoch 31/200\n",
      "88/88 - 0s - loss: 2.0310\n",
      "Epoch 32/200\n",
      "88/88 - 0s - loss: 2.0278\n",
      "Epoch 33/200\n",
      "88/88 - 0s - loss: 2.0248\n",
      "Epoch 34/200\n",
      "88/88 - 0s - loss: 2.0196\n",
      "Epoch 35/200\n",
      "88/88 - 0s - loss: 2.0157\n",
      "Epoch 36/200\n",
      "88/88 - 0s - loss: 2.0115\n",
      "Epoch 37/200\n",
      "88/88 - 0s - loss: 2.0091\n",
      "Epoch 38/200\n",
      "88/88 - 0s - loss: 2.0063\n",
      "Epoch 39/200\n",
      "88/88 - 0s - loss: 2.0032\n",
      "Epoch 40/200\n",
      "88/88 - 0s - loss: 1.9996\n",
      "Epoch 41/200\n",
      "88/88 - 0s - loss: 1.9966\n",
      "Epoch 42/200\n",
      "88/88 - 0s - loss: 1.9942\n",
      "Epoch 43/200\n",
      "88/88 - 0s - loss: 1.9914\n",
      "Epoch 44/200\n",
      "88/88 - 0s - loss: 1.9906\n",
      "Epoch 45/200\n",
      "88/88 - 0s - loss: 1.9898\n",
      "Epoch 46/200\n",
      "88/88 - 0s - loss: 1.9871\n",
      "Epoch 47/200\n",
      "88/88 - 0s - loss: 1.9837\n",
      "Epoch 48/200\n",
      "88/88 - 0s - loss: 1.9816\n",
      "Epoch 49/200\n",
      "88/88 - 0s - loss: 1.9814\n",
      "Epoch 50/200\n",
      "88/88 - 0s - loss: 1.9786\n",
      "Epoch 51/200\n",
      "88/88 - 0s - loss: 1.9768\n",
      "Epoch 52/200\n",
      "88/88 - 0s - loss: 1.9760\n",
      "Epoch 53/200\n",
      "88/88 - 0s - loss: 1.9741\n",
      "Epoch 54/200\n",
      "88/88 - 0s - loss: 1.9741\n",
      "Epoch 55/200\n",
      "88/88 - 0s - loss: 1.9708\n",
      "Epoch 56/200\n",
      "88/88 - 0s - loss: 1.9725\n",
      "Epoch 57/200\n",
      "88/88 - 0s - loss: 1.9685\n",
      "Epoch 58/200\n",
      "88/88 - 0s - loss: 1.9657\n",
      "Epoch 59/200\n",
      "88/88 - 0s - loss: 1.9665\n",
      "Epoch 60/200\n",
      "88/88 - 0s - loss: 1.9651\n",
      "Epoch 61/200\n",
      "88/88 - 0s - loss: 1.9632\n",
      "Epoch 62/200\n",
      "88/88 - 0s - loss: 1.9616\n",
      "Epoch 63/200\n",
      "88/88 - 0s - loss: 1.9615\n",
      "Epoch 64/200\n",
      "88/88 - 0s - loss: 1.9607\n",
      "Epoch 65/200\n",
      "88/88 - 0s - loss: 1.9619\n",
      "Epoch 66/200\n",
      "88/88 - 0s - loss: 1.9599\n",
      "Epoch 67/200\n",
      "88/88 - 0s - loss: 1.9588\n",
      "Epoch 68/200\n",
      "88/88 - 0s - loss: 1.9568\n",
      "Epoch 69/200\n",
      "88/88 - 0s - loss: 1.9559\n",
      "Epoch 70/200\n",
      "88/88 - 0s - loss: 1.9595\n",
      "Epoch 71/200\n",
      "88/88 - 0s - loss: 1.9553\n",
      "Epoch 72/200\n",
      "88/88 - 0s - loss: 1.9545\n",
      "Epoch 73/200\n",
      "88/88 - 0s - loss: 1.9531\n",
      "Epoch 74/200\n",
      "88/88 - 0s - loss: 1.9520\n",
      "Epoch 75/200\n",
      "88/88 - 0s - loss: 1.9518\n",
      "Epoch 76/200\n",
      "88/88 - 0s - loss: 1.9515\n",
      "Epoch 77/200\n",
      "88/88 - 0s - loss: 1.9509\n",
      "Epoch 78/200\n",
      "88/88 - 0s - loss: 1.9508\n",
      "Epoch 79/200\n",
      "88/88 - 0s - loss: 1.9484\n",
      "Epoch 80/200\n",
      "88/88 - 0s - loss: 1.9470\n",
      "Epoch 81/200\n",
      "88/88 - 0s - loss: 1.9461\n",
      "Epoch 82/200\n",
      "88/88 - 0s - loss: 1.9475\n",
      "Epoch 83/200\n",
      "88/88 - 0s - loss: 1.9457\n",
      "Epoch 84/200\n",
      "88/88 - 0s - loss: 1.9471\n",
      "Epoch 85/200\n",
      "88/88 - 0s - loss: 1.9485\n",
      "Epoch 86/200\n",
      "88/88 - 0s - loss: 1.9469\n",
      "Epoch 87/200\n",
      "88/88 - 0s - loss: 1.9458\n",
      "Epoch 88/200\n",
      "88/88 - 0s - loss: 1.9444\n",
      "Epoch 89/200\n",
      "88/88 - 0s - loss: 1.9423\n",
      "Epoch 90/200\n",
      "88/88 - 0s - loss: 1.9417\n",
      "Epoch 91/200\n",
      "88/88 - 0s - loss: 1.9415\n",
      "Epoch 92/200\n",
      "88/88 - 0s - loss: 1.9416\n",
      "Epoch 93/200\n",
      "88/88 - 0s - loss: 1.9437\n",
      "Epoch 94/200\n",
      "88/88 - 0s - loss: 1.9419\n",
      "Epoch 95/200\n",
      "88/88 - 0s - loss: 1.9409\n",
      "Epoch 96/200\n",
      "88/88 - 0s - loss: 1.9402\n",
      "Epoch 97/200\n",
      "88/88 - 0s - loss: 1.9394\n",
      "Epoch 98/200\n",
      "88/88 - 0s - loss: 1.9387\n",
      "Epoch 99/200\n",
      "88/88 - 0s - loss: 1.9433\n",
      "Epoch 100/200\n",
      "88/88 - 0s - loss: 1.9383\n",
      "Epoch 101/200\n",
      "88/88 - 0s - loss: 1.9391\n",
      "Epoch 102/200\n",
      "88/88 - 0s - loss: 1.9391\n",
      "Epoch 103/200\n",
      "88/88 - 0s - loss: 1.9374\n",
      "Epoch 104/200\n",
      "88/88 - 0s - loss: 1.9381\n",
      "Epoch 105/200\n",
      "88/88 - 0s - loss: 1.9383\n",
      "Epoch 106/200\n",
      "88/88 - 0s - loss: 1.9361\n",
      "Epoch 107/200\n",
      "88/88 - 0s - loss: 1.9384\n",
      "Epoch 108/200\n",
      "88/88 - 0s - loss: 1.9352\n",
      "Epoch 109/200\n",
      "88/88 - 0s - loss: 1.9352\n",
      "Epoch 110/200\n",
      "88/88 - 0s - loss: 1.9376\n",
      "Epoch 111/200\n",
      "88/88 - 0s - loss: 1.9363\n",
      "Epoch 112/200\n",
      "88/88 - 0s - loss: 1.9359\n",
      "Epoch 113/200\n",
      "88/88 - 0s - loss: 1.9355\n",
      "Epoch 114/200\n",
      "88/88 - 0s - loss: 1.9334\n",
      "Epoch 115/200\n",
      "88/88 - 0s - loss: 1.9358\n",
      "Epoch 116/200\n",
      "88/88 - 0s - loss: 1.9347\n",
      "Epoch 117/200\n",
      "88/88 - 0s - loss: 1.9312\n",
      "Epoch 118/200\n",
      "88/88 - 0s - loss: 1.9330\n",
      "Epoch 119/200\n",
      "88/88 - 0s - loss: 1.9312\n",
      "Epoch 120/200\n",
      "88/88 - 0s - loss: 1.9336\n",
      "Epoch 121/200\n",
      "88/88 - 0s - loss: 1.9305\n",
      "Epoch 122/200\n",
      "88/88 - 0s - loss: 1.9333\n",
      "Epoch 123/200\n",
      "88/88 - 0s - loss: 1.9314\n",
      "Epoch 124/200\n",
      "88/88 - 0s - loss: 1.9315\n",
      "Epoch 125/200\n",
      "88/88 - 0s - loss: 1.9314\n",
      "Epoch 126/200\n",
      "88/88 - 0s - loss: 1.9302\n",
      "Epoch 127/200\n",
      "88/88 - 0s - loss: 1.9314\n",
      "Epoch 128/200\n",
      "88/88 - 0s - loss: 1.9297\n",
      "Epoch 129/200\n",
      "88/88 - 0s - loss: 1.9319\n",
      "Epoch 130/200\n",
      "88/88 - 0s - loss: 1.9297\n",
      "Epoch 131/200\n",
      "88/88 - 0s - loss: 1.9284\n",
      "Epoch 132/200\n",
      "88/88 - 0s - loss: 1.9297\n",
      "Epoch 133/200\n",
      "88/88 - 0s - loss: 1.9297\n",
      "Epoch 134/200\n",
      "88/88 - 0s - loss: 1.9260\n",
      "Epoch 135/200\n",
      "88/88 - 0s - loss: 1.9307\n",
      "Epoch 136/200\n",
      "88/88 - 0s - loss: 1.9287\n",
      "Epoch 137/200\n",
      "88/88 - 0s - loss: 1.9277\n",
      "Epoch 138/200\n",
      "88/88 - 0s - loss: 1.9276\n",
      "Epoch 139/200\n",
      "88/88 - 0s - loss: 1.9302\n",
      "Epoch 140/200\n",
      "88/88 - 0s - loss: 1.9272\n",
      "Epoch 141/200\n",
      "88/88 - 0s - loss: 1.9275\n",
      "Epoch 142/200\n",
      "88/88 - 0s - loss: 1.9287\n",
      "Epoch 143/200\n",
      "88/88 - 0s - loss: 1.9306\n",
      "Epoch 144/200\n",
      "88/88 - 0s - loss: 1.9283\n",
      "Epoch 145/200\n",
      "88/88 - 0s - loss: 1.9289\n",
      "Epoch 146/200\n",
      "88/88 - 0s - loss: 1.9267\n",
      "Epoch 147/200\n",
      "88/88 - 0s - loss: 1.9274\n",
      "Epoch 148/200\n",
      "88/88 - 0s - loss: 1.9250\n",
      "Epoch 149/200\n",
      "88/88 - 0s - loss: 1.9272\n",
      "Epoch 150/200\n",
      "88/88 - 0s - loss: 1.9263\n",
      "Epoch 151/200\n",
      "88/88 - 0s - loss: 1.9264\n",
      "Epoch 152/200\n",
      "88/88 - 0s - loss: 1.9247\n",
      "Epoch 153/200\n",
      "88/88 - 0s - loss: 1.9247\n",
      "Epoch 154/200\n",
      "88/88 - 0s - loss: 1.9244\n",
      "Epoch 155/200\n",
      "88/88 - 0s - loss: 1.9263\n",
      "Epoch 156/200\n",
      "88/88 - 0s - loss: 1.9242\n",
      "Epoch 157/200\n",
      "88/88 - 0s - loss: 1.9248\n",
      "Epoch 158/200\n",
      "88/88 - 0s - loss: 1.9246\n",
      "Epoch 159/200\n",
      "88/88 - 0s - loss: 1.9256\n",
      "Epoch 160/200\n",
      "88/88 - 0s - loss: 1.9230\n",
      "Epoch 161/200\n",
      "88/88 - 0s - loss: 1.9249\n",
      "Epoch 162/200\n",
      "88/88 - 0s - loss: 1.9262\n",
      "Epoch 163/200\n",
      "88/88 - 0s - loss: 1.9241\n",
      "Epoch 164/200\n",
      "88/88 - 0s - loss: 1.9251\n",
      "Epoch 165/200\n",
      "88/88 - 0s - loss: 1.9239\n",
      "Epoch 166/200\n",
      "88/88 - 0s - loss: 1.9245\n",
      "Epoch 167/200\n",
      "88/88 - 0s - loss: 1.9257\n",
      "Epoch 168/200\n",
      "88/88 - 0s - loss: 1.9245\n",
      "Epoch 169/200\n",
      "88/88 - 0s - loss: 1.9237\n",
      "Epoch 170/200\n",
      "88/88 - 0s - loss: 1.9228\n",
      "Epoch 171/200\n",
      "88/88 - 0s - loss: 1.9227\n",
      "Epoch 172/200\n",
      "88/88 - 0s - loss: 1.9247\n",
      "Epoch 173/200\n",
      "88/88 - 0s - loss: 1.9227\n",
      "Epoch 174/200\n",
      "88/88 - 0s - loss: 1.9236\n",
      "Epoch 175/200\n",
      "88/88 - 0s - loss: 1.9224\n",
      "Epoch 176/200\n",
      "88/88 - 0s - loss: 1.9235\n",
      "Epoch 177/200\n",
      "88/88 - 0s - loss: 1.9223\n",
      "Epoch 178/200\n",
      "88/88 - 0s - loss: 1.9232\n",
      "Epoch 179/200\n",
      "88/88 - 0s - loss: 1.9220\n",
      "Epoch 180/200\n",
      "88/88 - 0s - loss: 1.9216\n",
      "Epoch 181/200\n",
      "88/88 - 0s - loss: 1.9214\n",
      "Epoch 182/200\n",
      "88/88 - 0s - loss: 1.9226\n",
      "Epoch 183/200\n",
      "88/88 - 0s - loss: 1.9219\n",
      "Epoch 184/200\n",
      "88/88 - 0s - loss: 1.9227\n",
      "Epoch 185/200\n",
      "88/88 - 0s - loss: 1.9211\n",
      "Epoch 186/200\n",
      "88/88 - 0s - loss: 1.9230\n",
      "Epoch 187/200\n",
      "88/88 - 0s - loss: 1.9214\n",
      "Epoch 188/200\n",
      "88/88 - 0s - loss: 1.9221\n",
      "Epoch 189/200\n",
      "88/88 - 0s - loss: 1.9211\n",
      "Epoch 190/200\n",
      "88/88 - 0s - loss: 1.9210\n",
      "Epoch 191/200\n",
      "88/88 - 0s - loss: 1.9201\n",
      "Epoch 192/200\n",
      "88/88 - 0s - loss: 1.9228\n",
      "Epoch 193/200\n",
      "88/88 - 0s - loss: 1.9200\n",
      "Epoch 194/200\n",
      "88/88 - 0s - loss: 1.9216\n",
      "Epoch 195/200\n",
      "88/88 - 0s - loss: 1.9217\n",
      "Epoch 196/200\n",
      "88/88 - 0s - loss: 1.9210\n",
      "Epoch 197/200\n",
      "88/88 - 0s - loss: 1.9192\n",
      "Epoch 198/200\n",
      "88/88 - 0s - loss: 1.9203\n",
      "Epoch 199/200\n",
      "88/88 - 0s - loss: 1.9198\n",
      "Epoch 200/200\n",
      "88/88 - 0s - loss: 1.9205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15291b6c288>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.fit(features_train, target_train, epochs=200, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02d4523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.268\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(features_test)\n",
    "predict = argmax(predict, axis=-1).astype('int')\n",
    "acc = accuracy_score(target_test, predict)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaeab95",
   "metadata": {},
   "source": [
    "### Combined Regression and Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aed596b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = LabelEncoder().fit_transform(target)\n",
    "n_class = len(unique(y_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b139517",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test, target_train_class, target_test_class = train_test_split(features, target, y_class, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54e418e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(n_features,))\n",
    "hidden1 = Dense(20, activation='relu', kernel_initializer='he_normal')(visible)\n",
    "hidden2 = Dense(10, activation='relu', kernel_initializer='he_normal')(hidden1)\n",
    "# regression output\n",
    "out_reg = Dense(1, activation='linear')(hidden2)\n",
    "# classification output\n",
    "out_clas = Dense(n_class, activation='softmax')(hidden2)\n",
    "# define model\n",
    "model = Model(inputs=visible, outputs=[out_reg, out_clas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f0bfa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse','sparse_categorical_crossentropy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0645acfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fcb0f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "88/88 - 1s - loss: 93.9490 - dense_8_loss: 90.6552 - dense_9_loss: 3.2938\n",
      "Epoch 2/150\n",
      "88/88 - 0s - loss: 69.9337 - dense_8_loss: 66.6471 - dense_9_loss: 3.2865\n",
      "Epoch 3/150\n",
      "88/88 - 0s - loss: 30.3265 - dense_8_loss: 27.3321 - dense_9_loss: 2.9945\n",
      "Epoch 4/150\n",
      "88/88 - 0s - loss: 11.8318 - dense_8_loss: 9.1737 - dense_9_loss: 2.6581\n",
      "Epoch 5/150\n",
      "88/88 - 0s - loss: 10.0018 - dense_8_loss: 7.4808 - dense_9_loss: 2.5210\n",
      "Epoch 6/150\n",
      "88/88 - 0s - loss: 9.7153 - dense_8_loss: 7.2492 - dense_9_loss: 2.4661\n",
      "Epoch 7/150\n",
      "88/88 - 0s - loss: 9.4673 - dense_8_loss: 7.0284 - dense_9_loss: 2.4389\n",
      "Epoch 8/150\n",
      "88/88 - 0s - loss: 9.2648 - dense_8_loss: 6.8497 - dense_9_loss: 2.4151\n",
      "Epoch 9/150\n",
      "88/88 - 0s - loss: 9.1031 - dense_8_loss: 6.7052 - dense_9_loss: 2.3979\n",
      "Epoch 10/150\n",
      "88/88 - 0s - loss: 8.9695 - dense_8_loss: 6.5864 - dense_9_loss: 2.3831\n",
      "Epoch 11/150\n",
      "88/88 - 0s - loss: 8.8506 - dense_8_loss: 6.4794 - dense_9_loss: 2.3712\n",
      "Epoch 12/150\n",
      "88/88 - 0s - loss: 8.7411 - dense_8_loss: 6.3777 - dense_9_loss: 2.3635\n",
      "Epoch 13/150\n",
      "88/88 - 0s - loss: 8.6340 - dense_8_loss: 6.2762 - dense_9_loss: 2.3577\n",
      "Epoch 14/150\n",
      "88/88 - 0s - loss: 8.5550 - dense_8_loss: 6.2035 - dense_9_loss: 2.3515\n",
      "Epoch 15/150\n",
      "88/88 - 0s - loss: 8.4383 - dense_8_loss: 6.0889 - dense_9_loss: 2.3494\n",
      "Epoch 16/150\n",
      "88/88 - 0s - loss: 8.3523 - dense_8_loss: 6.0068 - dense_9_loss: 2.3455\n",
      "Epoch 17/150\n",
      "88/88 - 0s - loss: 8.2514 - dense_8_loss: 5.9069 - dense_9_loss: 2.3445\n",
      "Epoch 18/150\n",
      "88/88 - 0s - loss: 8.1547 - dense_8_loss: 5.8109 - dense_9_loss: 2.3438\n",
      "Epoch 19/150\n",
      "88/88 - 0s - loss: 8.0556 - dense_8_loss: 5.7150 - dense_9_loss: 2.3405\n",
      "Epoch 20/150\n",
      "88/88 - 0s - loss: 7.9685 - dense_8_loss: 5.6302 - dense_9_loss: 2.3383\n",
      "Epoch 21/150\n",
      "88/88 - 0s - loss: 7.8820 - dense_8_loss: 5.5454 - dense_9_loss: 2.3367\n",
      "Epoch 22/150\n",
      "88/88 - 0s - loss: 7.8065 - dense_8_loss: 5.4686 - dense_9_loss: 2.3379\n",
      "Epoch 23/150\n",
      "88/88 - 0s - loss: 7.7215 - dense_8_loss: 5.3850 - dense_9_loss: 2.3365\n",
      "Epoch 24/150\n",
      "88/88 - 0s - loss: 7.6535 - dense_8_loss: 5.3192 - dense_9_loss: 2.3343\n",
      "Epoch 25/150\n",
      "88/88 - 0s - loss: 7.6054 - dense_8_loss: 5.2714 - dense_9_loss: 2.3340\n",
      "Epoch 26/150\n",
      "88/88 - 0s - loss: 7.5192 - dense_8_loss: 5.1881 - dense_9_loss: 2.3311\n",
      "Epoch 27/150\n",
      "88/88 - 0s - loss: 7.4683 - dense_8_loss: 5.1373 - dense_9_loss: 2.3309\n",
      "Epoch 28/150\n",
      "88/88 - 0s - loss: 7.4641 - dense_8_loss: 5.1356 - dense_9_loss: 2.3284\n",
      "Epoch 29/150\n",
      "88/88 - 0s - loss: 7.3800 - dense_8_loss: 5.0536 - dense_9_loss: 2.3264\n",
      "Epoch 30/150\n",
      "88/88 - 0s - loss: 7.3286 - dense_8_loss: 5.0040 - dense_9_loss: 2.3245\n",
      "Epoch 31/150\n",
      "88/88 - 0s - loss: 7.2842 - dense_8_loss: 4.9614 - dense_9_loss: 2.3228\n",
      "Epoch 32/150\n",
      "88/88 - 0s - loss: 7.2538 - dense_8_loss: 4.9338 - dense_9_loss: 2.3200\n",
      "Epoch 33/150\n",
      "88/88 - 0s - loss: 7.2543 - dense_8_loss: 4.9387 - dense_9_loss: 2.3157\n",
      "Epoch 34/150\n",
      "88/88 - 0s - loss: 7.1962 - dense_8_loss: 4.8852 - dense_9_loss: 2.3110\n",
      "Epoch 35/150\n",
      "88/88 - 0s - loss: 7.1454 - dense_8_loss: 4.8490 - dense_9_loss: 2.2963\n",
      "Epoch 36/150\n",
      "88/88 - 0s - loss: 7.1377 - dense_8_loss: 4.8545 - dense_9_loss: 2.2832\n",
      "Epoch 37/150\n",
      "88/88 - 0s - loss: 7.0698 - dense_8_loss: 4.8006 - dense_9_loss: 2.2693\n",
      "Epoch 38/150\n",
      "88/88 - 0s - loss: 7.0497 - dense_8_loss: 4.7927 - dense_9_loss: 2.2569\n",
      "Epoch 39/150\n",
      "88/88 - 0s - loss: 7.0120 - dense_8_loss: 4.7663 - dense_9_loss: 2.2457\n",
      "Epoch 40/150\n",
      "88/88 - 0s - loss: 7.0011 - dense_8_loss: 4.7678 - dense_9_loss: 2.2333\n",
      "Epoch 41/150\n",
      "88/88 - 0s - loss: 6.9718 - dense_8_loss: 4.7496 - dense_9_loss: 2.2222\n",
      "Epoch 42/150\n",
      "88/88 - 0s - loss: 6.9603 - dense_8_loss: 4.7476 - dense_9_loss: 2.2127\n",
      "Epoch 43/150\n",
      "88/88 - 0s - loss: 6.9445 - dense_8_loss: 4.7418 - dense_9_loss: 2.2026\n",
      "Epoch 44/150\n",
      "88/88 - 0s - loss: 6.9300 - dense_8_loss: 4.7361 - dense_9_loss: 2.1939\n",
      "Epoch 45/150\n",
      "88/88 - 0s - loss: 6.8993 - dense_8_loss: 4.7145 - dense_9_loss: 2.1848\n",
      "Epoch 46/150\n",
      "88/88 - 0s - loss: 6.8761 - dense_8_loss: 4.6986 - dense_9_loss: 2.1776\n",
      "Epoch 47/150\n",
      "88/88 - 0s - loss: 6.8813 - dense_8_loss: 4.7123 - dense_9_loss: 2.1690\n",
      "Epoch 48/150\n",
      "88/88 - 0s - loss: 6.8465 - dense_8_loss: 4.6838 - dense_9_loss: 2.1626\n",
      "Epoch 49/150\n",
      "88/88 - 0s - loss: 6.8444 - dense_8_loss: 4.6901 - dense_9_loss: 2.1544\n",
      "Epoch 50/150\n",
      "88/88 - 0s - loss: 6.8118 - dense_8_loss: 4.6644 - dense_9_loss: 2.1474\n",
      "Epoch 51/150\n",
      "88/88 - 0s - loss: 6.7996 - dense_8_loss: 4.6594 - dense_9_loss: 2.1401\n",
      "Epoch 52/150\n",
      "88/88 - 0s - loss: 6.7973 - dense_8_loss: 4.6632 - dense_9_loss: 2.1341\n",
      "Epoch 53/150\n",
      "88/88 - 0s - loss: 6.7559 - dense_8_loss: 4.6267 - dense_9_loss: 2.1292\n",
      "Epoch 54/150\n",
      "88/88 - 0s - loss: 6.7686 - dense_8_loss: 4.6454 - dense_9_loss: 2.1232\n",
      "Epoch 55/150\n",
      "88/88 - 0s - loss: 6.7786 - dense_8_loss: 4.6607 - dense_9_loss: 2.1178\n",
      "Epoch 56/150\n",
      "88/88 - 0s - loss: 6.7709 - dense_8_loss: 4.6566 - dense_9_loss: 2.1143\n",
      "Epoch 57/150\n",
      "88/88 - 0s - loss: 6.7402 - dense_8_loss: 4.6343 - dense_9_loss: 2.1059\n",
      "Epoch 58/150\n",
      "88/88 - 0s - loss: 6.7327 - dense_8_loss: 4.6307 - dense_9_loss: 2.1020\n",
      "Epoch 59/150\n",
      "88/88 - 0s - loss: 6.7198 - dense_8_loss: 4.6216 - dense_9_loss: 2.0982\n",
      "Epoch 60/150\n",
      "88/88 - 0s - loss: 6.7007 - dense_8_loss: 4.6069 - dense_9_loss: 2.0938\n",
      "Epoch 61/150\n",
      "88/88 - 0s - loss: 6.7282 - dense_8_loss: 4.6381 - dense_9_loss: 2.0902\n",
      "Epoch 62/150\n",
      "88/88 - 0s - loss: 6.7224 - dense_8_loss: 4.6369 - dense_9_loss: 2.0855\n",
      "Epoch 63/150\n",
      "88/88 - 0s - loss: 6.6844 - dense_8_loss: 4.6025 - dense_9_loss: 2.0819\n",
      "Epoch 64/150\n",
      "88/88 - 0s - loss: 6.6985 - dense_8_loss: 4.6192 - dense_9_loss: 2.0794\n",
      "Epoch 65/150\n",
      "88/88 - 0s - loss: 6.6666 - dense_8_loss: 4.5914 - dense_9_loss: 2.0752\n",
      "Epoch 66/150\n",
      "88/88 - 0s - loss: 6.6929 - dense_8_loss: 4.6206 - dense_9_loss: 2.0723\n",
      "Epoch 67/150\n",
      "88/88 - 0s - loss: 6.6745 - dense_8_loss: 4.6057 - dense_9_loss: 2.0688\n",
      "Epoch 68/150\n",
      "88/88 - 0s - loss: 6.6705 - dense_8_loss: 4.6038 - dense_9_loss: 2.0668\n",
      "Epoch 69/150\n",
      "88/88 - 0s - loss: 6.6871 - dense_8_loss: 4.6253 - dense_9_loss: 2.0619\n",
      "Epoch 70/150\n",
      "88/88 - 0s - loss: 6.6808 - dense_8_loss: 4.6194 - dense_9_loss: 2.0614\n",
      "Epoch 71/150\n",
      "88/88 - 0s - loss: 6.6527 - dense_8_loss: 4.5964 - dense_9_loss: 2.0563\n",
      "Epoch 72/150\n",
      "88/88 - 0s - loss: 6.6505 - dense_8_loss: 4.5957 - dense_9_loss: 2.0548\n",
      "Epoch 73/150\n",
      "88/88 - 0s - loss: 6.6535 - dense_8_loss: 4.6003 - dense_9_loss: 2.0532\n",
      "Epoch 74/150\n",
      "88/88 - 0s - loss: 6.6575 - dense_8_loss: 4.6053 - dense_9_loss: 2.0522\n",
      "Epoch 75/150\n",
      "88/88 - 0s - loss: 6.6332 - dense_8_loss: 4.5856 - dense_9_loss: 2.0476\n",
      "Epoch 76/150\n",
      "88/88 - 0s - loss: 6.6418 - dense_8_loss: 4.5950 - dense_9_loss: 2.0468\n",
      "Epoch 77/150\n",
      "88/88 - 0s - loss: 6.6262 - dense_8_loss: 4.5827 - dense_9_loss: 2.0435\n",
      "Epoch 78/150\n",
      "88/88 - 0s - loss: 6.6208 - dense_8_loss: 4.5787 - dense_9_loss: 2.0421\n",
      "Epoch 79/150\n",
      "88/88 - 0s - loss: 6.6395 - dense_8_loss: 4.5986 - dense_9_loss: 2.0410\n",
      "Epoch 80/150\n",
      "88/88 - 0s - loss: 6.6168 - dense_8_loss: 4.5813 - dense_9_loss: 2.0355\n",
      "Epoch 81/150\n",
      "88/88 - 0s - loss: 6.6132 - dense_8_loss: 4.5765 - dense_9_loss: 2.0367\n",
      "Epoch 82/150\n",
      "88/88 - 0s - loss: 6.6540 - dense_8_loss: 4.6190 - dense_9_loss: 2.0349\n",
      "Epoch 83/150\n",
      "88/88 - 0s - loss: 6.6214 - dense_8_loss: 4.5892 - dense_9_loss: 2.0321\n",
      "Epoch 84/150\n",
      "88/88 - 0s - loss: 6.6086 - dense_8_loss: 4.5788 - dense_9_loss: 2.0299\n",
      "Epoch 85/150\n",
      "88/88 - 0s - loss: 6.6319 - dense_8_loss: 4.6022 - dense_9_loss: 2.0296\n",
      "Epoch 86/150\n",
      "88/88 - 0s - loss: 6.5880 - dense_8_loss: 4.5625 - dense_9_loss: 2.0255\n",
      "Epoch 87/150\n",
      "88/88 - 0s - loss: 6.5931 - dense_8_loss: 4.5676 - dense_9_loss: 2.0256\n",
      "Epoch 88/150\n",
      "88/88 - 0s - loss: 6.6050 - dense_8_loss: 4.5806 - dense_9_loss: 2.0243\n",
      "Epoch 89/150\n",
      "88/88 - 0s - loss: 6.5921 - dense_8_loss: 4.5696 - dense_9_loss: 2.0225\n",
      "Epoch 90/150\n",
      "88/88 - 0s - loss: 6.5899 - dense_8_loss: 4.5697 - dense_9_loss: 2.0202\n",
      "Epoch 91/150\n",
      "88/88 - 0s - loss: 6.5759 - dense_8_loss: 4.5562 - dense_9_loss: 2.0198\n",
      "Epoch 92/150\n",
      "88/88 - 0s - loss: 6.5754 - dense_8_loss: 4.5585 - dense_9_loss: 2.0170\n",
      "Epoch 93/150\n",
      "88/88 - 0s - loss: 6.5832 - dense_8_loss: 4.5656 - dense_9_loss: 2.0175\n",
      "Epoch 94/150\n",
      "88/88 - 0s - loss: 6.5789 - dense_8_loss: 4.5637 - dense_9_loss: 2.0152\n",
      "Epoch 95/150\n",
      "88/88 - 0s - loss: 6.6027 - dense_8_loss: 4.5883 - dense_9_loss: 2.0144\n",
      "Epoch 96/150\n",
      "88/88 - 0s - loss: 6.5776 - dense_8_loss: 4.5644 - dense_9_loss: 2.0132\n",
      "Epoch 97/150\n",
      "88/88 - 0s - loss: 6.5594 - dense_8_loss: 4.5475 - dense_9_loss: 2.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/150\n",
      "88/88 - 0s - loss: 6.5823 - dense_8_loss: 4.5718 - dense_9_loss: 2.0105\n",
      "Epoch 99/150\n",
      "88/88 - 0s - loss: 6.5684 - dense_8_loss: 4.5588 - dense_9_loss: 2.0095\n",
      "Epoch 100/150\n",
      "88/88 - 0s - loss: 6.5656 - dense_8_loss: 4.5577 - dense_9_loss: 2.0079\n",
      "Epoch 101/150\n",
      "88/88 - 0s - loss: 6.5628 - dense_8_loss: 4.5560 - dense_9_loss: 2.0067\n",
      "Epoch 102/150\n",
      "88/88 - 0s - loss: 6.5574 - dense_8_loss: 4.5518 - dense_9_loss: 2.0056\n",
      "Epoch 103/150\n",
      "88/88 - 0s - loss: 6.5398 - dense_8_loss: 4.5371 - dense_9_loss: 2.0027\n",
      "Epoch 104/150\n",
      "88/88 - 0s - loss: 6.5727 - dense_8_loss: 4.5676 - dense_9_loss: 2.0051\n",
      "Epoch 105/150\n",
      "88/88 - 0s - loss: 6.5615 - dense_8_loss: 4.5566 - dense_9_loss: 2.0049\n",
      "Epoch 106/150\n",
      "88/88 - 0s - loss: 6.5600 - dense_8_loss: 4.5577 - dense_9_loss: 2.0023\n",
      "Epoch 107/150\n",
      "88/88 - 0s - loss: 6.5531 - dense_8_loss: 4.5524 - dense_9_loss: 2.0007\n",
      "Epoch 108/150\n",
      "88/88 - 0s - loss: 6.5682 - dense_8_loss: 4.5667 - dense_9_loss: 2.0015\n",
      "Epoch 109/150\n",
      "88/88 - 0s - loss: 6.5570 - dense_8_loss: 4.5573 - dense_9_loss: 1.9996\n",
      "Epoch 110/150\n",
      "88/88 - 0s - loss: 6.5476 - dense_8_loss: 4.5487 - dense_9_loss: 1.9990\n",
      "Epoch 111/150\n",
      "88/88 - 0s - loss: 6.5430 - dense_8_loss: 4.5448 - dense_9_loss: 1.9982\n",
      "Epoch 112/150\n",
      "88/88 - 0s - loss: 6.5341 - dense_8_loss: 4.5385 - dense_9_loss: 1.9956\n",
      "Epoch 113/150\n",
      "88/88 - 0s - loss: 6.5504 - dense_8_loss: 4.5550 - dense_9_loss: 1.9953\n",
      "Epoch 114/150\n",
      "88/88 - 0s - loss: 6.5433 - dense_8_loss: 4.5479 - dense_9_loss: 1.9955\n",
      "Epoch 115/150\n",
      "88/88 - 0s - loss: 6.5360 - dense_8_loss: 4.5437 - dense_9_loss: 1.9923\n",
      "Epoch 116/150\n",
      "88/88 - 0s - loss: 6.5340 - dense_8_loss: 4.5410 - dense_9_loss: 1.9931\n",
      "Epoch 117/150\n",
      "88/88 - 0s - loss: 6.5711 - dense_8_loss: 4.5757 - dense_9_loss: 1.9954\n",
      "Epoch 118/150\n",
      "88/88 - 0s - loss: 6.5352 - dense_8_loss: 4.5436 - dense_9_loss: 1.9915\n",
      "Epoch 119/150\n",
      "88/88 - 0s - loss: 6.5391 - dense_8_loss: 4.5481 - dense_9_loss: 1.9911\n",
      "Epoch 120/150\n",
      "88/88 - 0s - loss: 6.5594 - dense_8_loss: 4.5683 - dense_9_loss: 1.9911\n",
      "Epoch 121/150\n",
      "88/88 - 0s - loss: 6.5253 - dense_8_loss: 4.5348 - dense_9_loss: 1.9905\n",
      "Epoch 122/150\n",
      "88/88 - 0s - loss: 6.5369 - dense_8_loss: 4.5480 - dense_9_loss: 1.9889\n",
      "Epoch 123/150\n",
      "88/88 - 0s - loss: 6.5386 - dense_8_loss: 4.5507 - dense_9_loss: 1.9879\n",
      "Epoch 124/150\n",
      "88/88 - 0s - loss: 6.5241 - dense_8_loss: 4.5358 - dense_9_loss: 1.9883\n",
      "Epoch 125/150\n",
      "88/88 - 0s - loss: 6.5105 - dense_8_loss: 4.5237 - dense_9_loss: 1.9868\n",
      "Epoch 126/150\n",
      "88/88 - 0s - loss: 6.5361 - dense_8_loss: 4.5497 - dense_9_loss: 1.9864\n",
      "Epoch 127/150\n",
      "88/88 - 0s - loss: 6.5617 - dense_8_loss: 4.5724 - dense_9_loss: 1.9894\n",
      "Epoch 128/150\n",
      "88/88 - 0s - loss: 6.5191 - dense_8_loss: 4.5341 - dense_9_loss: 1.9850\n",
      "Epoch 129/150\n",
      "88/88 - 0s - loss: 6.5223 - dense_8_loss: 4.5374 - dense_9_loss: 1.9848\n",
      "Epoch 130/150\n",
      "88/88 - 0s - loss: 6.5043 - dense_8_loss: 4.5220 - dense_9_loss: 1.9824\n",
      "Epoch 131/150\n",
      "88/88 - 0s - loss: 6.5130 - dense_8_loss: 4.5299 - dense_9_loss: 1.9831\n",
      "Epoch 132/150\n",
      "88/88 - 0s - loss: 6.5229 - dense_8_loss: 4.5396 - dense_9_loss: 1.9834\n",
      "Epoch 133/150\n",
      "88/88 - 0s - loss: 6.5071 - dense_8_loss: 4.5267 - dense_9_loss: 1.9804\n",
      "Epoch 134/150\n",
      "88/88 - 0s - loss: 6.5057 - dense_8_loss: 4.5243 - dense_9_loss: 1.9814\n",
      "Epoch 135/150\n",
      "88/88 - 0s - loss: 6.5269 - dense_8_loss: 4.5450 - dense_9_loss: 1.9819\n",
      "Epoch 136/150\n",
      "88/88 - 0s - loss: 6.4990 - dense_8_loss: 4.5201 - dense_9_loss: 1.9789\n",
      "Epoch 137/150\n",
      "88/88 - 0s - loss: 6.5082 - dense_8_loss: 4.5281 - dense_9_loss: 1.9801\n",
      "Epoch 138/150\n",
      "88/88 - 0s - loss: 6.5019 - dense_8_loss: 4.5239 - dense_9_loss: 1.9780\n",
      "Epoch 139/150\n",
      "88/88 - 0s - loss: 6.5064 - dense_8_loss: 4.5270 - dense_9_loss: 1.9794\n",
      "Epoch 140/150\n",
      "88/88 - 0s - loss: 6.4867 - dense_8_loss: 4.5086 - dense_9_loss: 1.9781\n",
      "Epoch 141/150\n",
      "88/88 - 0s - loss: 6.5094 - dense_8_loss: 4.5320 - dense_9_loss: 1.9774\n",
      "Epoch 142/150\n",
      "88/88 - 0s - loss: 6.4946 - dense_8_loss: 4.5168 - dense_9_loss: 1.9777\n",
      "Epoch 143/150\n",
      "88/88 - 0s - loss: 6.5004 - dense_8_loss: 4.5244 - dense_9_loss: 1.9760\n",
      "Epoch 144/150\n",
      "88/88 - 0s - loss: 6.4937 - dense_8_loss: 4.5175 - dense_9_loss: 1.9761\n",
      "Epoch 145/150\n",
      "88/88 - 0s - loss: 6.5058 - dense_8_loss: 4.5300 - dense_9_loss: 1.9759\n",
      "Epoch 146/150\n",
      "88/88 - 0s - loss: 6.4882 - dense_8_loss: 4.5131 - dense_9_loss: 1.9751\n",
      "Epoch 147/150\n",
      "88/88 - 0s - loss: 6.5082 - dense_8_loss: 4.5331 - dense_9_loss: 1.9752\n",
      "Epoch 148/150\n",
      "88/88 - 0s - loss: 6.5223 - dense_8_loss: 4.5471 - dense_9_loss: 1.9752\n",
      "Epoch 149/150\n",
      "88/88 - 0s - loss: 6.5068 - dense_8_loss: 4.5327 - dense_9_loss: 1.9741\n",
      "Epoch 150/150\n",
      "88/88 - 0s - loss: 6.5099 - dense_8_loss: 4.5335 - dense_9_loss: 1.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15292df05c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train, [target_train,target_train_class], epochs=150, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f544121",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1, pred2 = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caffe59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.575\n",
      "Accuracy: 0.261\n"
     ]
    }
   ],
   "source": [
    "error = mean_absolute_error(target_test, pred1)\n",
    "print('MAE: %.3f' % error)\n",
    "# evaluate accuracy for classification model\n",
    "pred2 = argmax(pred2, axis=-1).astype('int')\n",
    "acc = accuracy_score(target_test_class, pred2)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807337fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
